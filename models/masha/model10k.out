Importing packages
/tmp/hostfile_41976187.undefined
Importing packages
Loaded the libraries.
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
/tmp/hostfile_41977724.undefined
Importing packages
Loaded the libraries.
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
load (3000000, 4, 2)
Loaded N = 100000 datapoints
Built the model.
Epoch 1/11
10/10 - 6s - loss: 2.9057 - val_loss: 2.6963 - 6s/epoch - 640ms/step
Epoch 2/11
10/10 - 2s - loss: 2.2846 - val_loss: 2.3119 - 2s/epoch - 184ms/step
Epoch 3/11
10/10 - 2s - loss: 1.6023 - val_loss: 1.8228 - 2s/epoch - 181ms/step
Epoch 4/11
10/10 - 2s - loss: 0.6570 - val_loss: 1.2661 - 2s/epoch - 179ms/step
Epoch 5/11
10/10 - 2s - loss: -3.3721e-02 - val_loss: 0.9953 - 2s/epoch - 186ms/step
Epoch 6/11
10/10 - 2s - loss: -3.1446e-01 - val_loss: 0.6976 - 2s/epoch - 185ms/step
Epoch 7/11
10/10 - 2s - loss: -8.2916e-01 - val_loss: 0.3295 - 2s/epoch - 184ms/step
Epoch 8/11
10/10 - 2s - loss: -1.4326e+00 - val_loss: -1.3873e-01 - 2s/epoch - 183ms/step
Epoch 9/11
10/10 - 2s - loss: -1.0341e+00 - val_loss: -5.0672e-01 - 2s/epoch - 182ms/step
Epoch 10/11

Epoch 10: saving model to models/masha/GDP_4day_NC15/checkpoint_epoch_10/weights
10/10 - 2s - loss: 1.5885 - val_loss: -6.8390e-02 - 2s/epoch - 197ms/step
Epoch 11/11
10/10 - 2s - loss: 2.0346 - val_loss: -7.1758e-01 - 2s/epoch - 183ms/step
Trained the model.
/tmp/hostfile_42014648.undefined
Importing packages
Loaded the libraries.
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
load (3000000, 4, 2)
load (3000000, 4, 2)
load (3000000, 4, 2)
load (3000000, 4, 2)
Loaded N = 10000000 datapoints
Built the model.
Epoch 1/11
977/977 - 179s - loss: -5.7511e-01 - val_loss: 1.7003 - 179s/epoch - 183ms/step
Epoch 2/11
977/977 - 173s - loss: 0.0249 - val_loss: -2.2632e+00 - 173s/epoch - 177ms/step
Epoch 3/11
977/977 - 174s - loss: -2.5786e+00 - val_loss: -2.9612e+00 - 174s/epoch - 178ms/step
Epoch 4/11
977/977 - 174s - loss: -2.4567e+00 - val_loss: -1.9928e-01 - 174s/epoch - 178ms/step
Epoch 5/11
977/977 - 172s - loss: -3.1208e+00 - val_loss: -4.9662e+00 - 172s/epoch - 176ms/step
Epoch 6/11
977/977 - 174s - loss: 0.6654 - val_loss: 3.2869 - 174s/epoch - 178ms/step
Epoch 7/11
977/977 - 173s - loss: 1.0936 - val_loss: -1.4682e+00 - 173s/epoch - 177ms/step
Epoch 8/11
977/977 - 173s - loss: -2.5393e+00 - val_loss: -3.2166e+00 - 173s/epoch - 177ms/step
Epoch 9/11
977/977 - 173s - loss: -2.6331e+00 - val_loss: -3.5244e+00 - 173s/epoch - 177ms/step
Epoch 10/11

Epoch 10: saving model to models/masha/GDP_4day_NC15/checkpoint_epoch_10/weights
977/977 - 173s - loss: -2.3337e+00 - val_loss: -2.2851e+00 - 173s/epoch - 177ms/step
Epoch 11/11
977/977 - 173s - loss: 10.1025 - val_loss: 2.6654 - 173s/epoch - 177ms/step
Trained the model.
/tmp/hostfile_42016333.undefined
Importing packages
Loaded the libraries.
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]
load (3000000, 4, 2)
Loaded N = 1000000 datapoints
Built the model.
Epoch 1/11
98/98 - 21s - loss: 0.4854 - val_loss: 0.1335 - 21s/epoch - 217ms/step
Epoch 2/11
98/98 - 17s - loss: -6.3426e-01 - val_loss: -1.0010e+00 - 17s/epoch - 173ms/step
Epoch 3/11
98/98 - 17s - loss: -1.1370e+00 - val_loss: 1.9695 - 17s/epoch - 173ms/step
Epoch 4/11
98/98 - 17s - loss: -1.2435e+00 - val_loss: -2.0473e+00 - 17s/epoch - 172ms/step
Epoch 5/11
98/98 - 17s - loss: -7.7643e-01 - val_loss: 2.3589 - 17s/epoch - 173ms/step
Epoch 6/11
98/98 - 17s - loss: 1.3679 - val_loss: 1.3711 - 17s/epoch - 173ms/step
Epoch 7/11
98/98 - 17s - loss: 0.2378 - val_loss: -1.3965e+00 - 17s/epoch - 172ms/step
Epoch 8/11
98/98 - 17s - loss: -1.6492e+00 - val_loss: -1.0981e+00 - 17s/epoch - 173ms/step
Epoch 9/11
98/98 - 17s - loss: -1.2973e+00 - val_loss: -2.2308e+00 - 17s/epoch - 173ms/step
Epoch 10/11

Epoch 10: saving model to models/masha/GDP_4day_NC15/checkpoint_epoch_10/weights
98/98 - 17s - loss: -1.7751e+00 - val_loss: 0.3658 - 17s/epoch - 175ms/step
Epoch 11/11
98/98 - 17s - loss: 3.0649 - val_loss: 2.7422 - 17s/epoch - 173ms/step
Trained the model.
/tmp/hostfile_42029823.undefined
