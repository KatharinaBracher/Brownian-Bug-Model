{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "tfkl = tf.keras.layers\n",
    "tfpl = tfp.layers\n",
    "tf.keras.backend.set_floatx(\"float64\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mdn(DT, N_C, user):\n",
    "    \"\"\"\n",
    "    Loads MDN model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [tfkl.Dense(256, activation='tanh'),\n",
    "         tfkl.Dense(256, activation='tanh'),\n",
    "         tfkl.Dense(256, activation='tanh'),\n",
    "         tfkl.Dense(256, activation='tanh'),\n",
    "         tfkl.Dense(512, activation='tanh'),\n",
    "         tfkl.Dense(512, activation='tanh'),\n",
    "         tfkl.Dense(N_C * 15, activation=None),\n",
    "         tfpl.MixtureSameFamily(N_C, tfpl.MultivariateNormalTriL(4))])\n",
    "\n",
    "    model.load_weights(\n",
    "        f\"../models/{user}/GDP_{DT:.0f}day_NC{N_C}/trained/weights.index\").expect_partial()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scalers(DT, N_C, user):\n",
    "    \"\"\"\n",
    "    Loads scaler objects relating to MDN models.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(f\"../models/{user}/GDP_{DT:.0f}day_NC{N_C}/Xscaler.pkl\", \"rb\") as file:\n",
    "        Xscaler = pickle.load(file)\n",
    "\n",
    "    with open(f\"../models/{user}/GDP_{DT:.0f}day_NC{N_C}/Yscaler.pkl\", \"rb\") as file:\n",
    "        Yscaler = pickle.load(file)\n",
    "    return Xscaler, Yscaler\n",
    "\n",
    "def given(X_1, X_0, Y_scaler, model):\n",
    "    \"\"\"\n",
    "    Evaluates transition density for fixed X_0.\n",
    "    \"\"\"\n",
    "    return Y_scaler.invert_standardisation_prob(\n",
    "        np.exp(\n",
    "            model.log_prob(\n",
    "                Y_scaler.standardise(X_1 - X_0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_position = array([[0.4],\n",
      "       [0.4],\n",
      "       [0.6],\n",
      "       [0.6]])\n",
      "B1_positions.shape = (2, 25)\n",
      "A1_positions.shape = (2, 25)\n",
      "updated_positions.shape = (4, 25)\n"
     ]
    }
   ],
   "source": [
    "# Model parameters.\n",
    "N_C = 32\n",
    "DT = 4\n",
    "user = \"masha\"\n",
    "\n",
    "# Load our trained model.\n",
    "model = load_mdn(DT, N_C, user)\n",
    "X_scaler, Y_scaler = load_scalers(DT, N_C, user)\n",
    "\n",
    "# Define the initial position of the first particle and the second particle.\n",
    "A0 = np.array([0.4, 0.4])\n",
    "# B0 = np.array([0.6, 0.6, 0.6, 0.6]).reshape(4, 1) \n",
    "B0 = np.array([0.6, 0.6])\n",
    "\n",
    "# Combine the initial positions to get a vector our model can understand.\n",
    "initial_position = np.hstack([A0, B0]).reshape(4, 1)\n",
    "print(f\"{initial_position = }\")\n",
    "\n",
    "model_at_init = model(X_scaler.standardise(initial_position))\n",
    "\n",
    "x = np.linspace(0, 1, 5)\n",
    "y = np.linspace(0, 1, 5)\n",
    "xx, yy = np.meshgrid(x, y, copy=True)\n",
    "\n",
    "B1_positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "print(f\"{B1_positions.shape = }\")\n",
    "\n",
    "# Fix the position of the second point, A1.\n",
    "A1 = np.array([0.5, 0.5]).reshape(2, 1)\n",
    "\n",
    "A1_positions = np.repeat(A1, 25, axis=1)\n",
    "print(f\"{A1_positions.shape = }\")\n",
    "\n",
    "updated_positions = np.vstack([A1_positions, B1_positions])\n",
    "print(f\"{updated_positions.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs.shape = (4, 25)\n"
     ]
    }
   ],
   "source": [
    "probs = np.zeros_like(updated_positions)\n",
    "\n",
    "for i in range(updated_positions.shape[1]):\n",
    "    p = updated_positions[:, i]\n",
    "    # print(p)\n",
    "    prob = given(p, initial_position, Y_scaler, model_at_init)\n",
    "    # print(prob, \"\\n\")\n",
    "\n",
    "    probs[:, i] = prob\n",
    "\n",
    "\n",
    "print(f\"{probs.shape = }\")\n",
    "\n",
    "# x0_probs = probs[:2, :].reshape((2, 25)) \n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.contourf(xx1, yy1, x0_probs, cmap='viridis')\n",
    "# plt.colorbar(label='Probability Density')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# plt.title('2D Gaussian Distribution')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
